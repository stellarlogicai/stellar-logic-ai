#!/usr/bin/env python3
"""
PERFORMANCE METRICS
Track actual costs per 10K sessions, infrastructure costs, latency under load
"""

import os
import time
import json
import psutil
import threading
import requests
import numpy as np
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor, as_completed
import logging

class PerformanceMetricsTracker:
    """Track comprehensive performance metrics for production system"""
    
    def __init__(self):
        self.base_path = "c:/Users/merce/Documents/helm-ai"
        self.production_path = os.path.join(self.base_path, "production")
        
        # Initialize logging
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(os.path.join(self.production_path, "logs/performance_metrics.log")),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
        
        # Performance metrics storage
        self.metrics = {
            'session_metrics': {
                'total_sessions': 0,
                'successful_sessions': 0,
                'failed_sessions': 0,
                'avg_session_duration_ms': 0,
                'sessions_per_hour': 0
            },
            'cost_metrics': {
                'infrastructure_costs_per_hour': 0.0,
                'compute_costs_per_10k_sessions': 0.0,
                'storage_costs_per_month': 0.0,
                'bandwidth_costs_per_gb': 0.0,
                'total_monthly_cost': 0.0
            },
            'latency_metrics': {
                'avg_response_time_ms': 0.0,
                'p95_response_time_ms': 0.0,
                'p99_response_time_ms': 0.0,
                'max_response_time_ms': 0.0,
                'min_response_time_ms': 0.0,
                'response_times': []
            },
            'throughput_metrics': {
                'requests_per_second': 0.0,
                'sessions_per_second': 0.0,
                'peak_throughput': 0.0,
                'sustained_throughput': 0.0
            },
            'resource_metrics': {
                'cpu_usage_percent': [],
                'memory_usage_percent': [],
                'disk_usage_percent': [],
                'network_io_mb_per_sec': 0.0,
                'avg_cpu_usage': 0.0,
                'avg_memory_usage': 0.0
            },
            'infrastructure_metrics': {
                'server_count': 1,
                'load_balancer_active': True,
                'database_connections': 0,
                'cache_hit_rate': 0.0,
                'uptime_percentage': 99.9
            }
        }
        
        # Cost calculation parameters
        self.cost_params = {
            'server_cost_per_hour': 0.05,  # $0.05/hour for small server
            'storage_cost_per_gb_per_month': 0.023,  # $0.023/GB/month
            'bandwidth_cost_per_gb': 0.09,  # $0.09/GB
            'database_cost_per_hour': 0.02,  # $0.02/hour
            'load_balancer_cost_per_hour': 0.025  # $0.025/hour
        }
        
        # Monitoring thread
        self.monitoring_active = False
        self.monitoring_thread = None
        
        self.logger.info("Performance Metrics Tracker initialized")
    
    def calculate_infrastructure_costs(self):
        """Calculate infrastructure costs based on current usage"""
        self.logger.info("Calculating infrastructure costs...")
        
        # Server costs
        server_cost_per_hour = (
            self.cost_params['server_cost_per_hour'] +
            self.cost_params['database_cost_per_hour'] +
            self.cost_params['load_balancer_cost_per_hour']
        )
        
        # Storage costs (models, logs, data)
        total_storage_gb = self.calculate_storage_usage()
        storage_cost_per_month = total_storage_gb * self.cost_params['storage_cost_per_gb_per_month']
        storage_cost_per_hour = storage_cost_per_month / (30 * 24)
        
        # Total hourly cost
        total_hourly_cost = server_cost_per_hour + storage_cost_per_hour
        
        # Cost per 10K sessions (assuming 100 sessions/hour)
        sessions_per_hour = 100
        hours_for_10k_sessions = 10000 / sessions_per_hour
        cost_per_10k_sessions = total_hourly_cost * hours_for_10k_sessions
        
        # Monthly cost estimate
        monthly_cost = total_hourly_cost * 24 * 30
        
        self.metrics['cost_metrics'].update({
            'infrastructure_costs_per_hour': total_hourly_cost,
            'compute_costs_per_10k_sessions': cost_per_10k_sessions,
            'storage_costs_per_month': storage_cost_per_month,
            'total_monthly_cost': monthly_cost
        })
        
        self.logger.info(f"Infrastructure costs calculated:")
        self.logger.info(f"  Hourly cost: ${total_hourly_cost:.4f}")
        self.logger.info(f"  Cost per 10K sessions: ${cost_per_10k_sessions:.2f}")
        self.logger.info(f"  Monthly cost: ${monthly_cost:.2f}")
    
    def calculate_storage_usage(self):
        """Calculate total storage usage in GB"""
        total_size_bytes = 0
        
        # Calculate models directory size
        models_dir = os.path.join(self.base_path, "models")
        if os.path.exists(models_dir):
            for root, dirs, files in os.walk(models_dir):
                for file in files:
                    file_path = os.path.join(root, file)
                    if os.path.exists(file_path):
                        total_size_bytes += os.path.getsize(file_path)
        
        # Calculate production directory size
        if os.path.exists(self.production_path):
            for root, dirs, files in os.walk(self.production_path):
                for file in files:
                    file_path = os.path.join(root, file)
                    if os.path.exists(file_path):
                        total_size_bytes += os.path.getsize(file_path)
        
        # Convert to GB
        total_size_gb = total_size_bytes / (1024 * 1024 * 1024)
        
        self.logger.info(f"Total storage usage: {total_size_gb:.2f} GB")
        return total_size_gb
    
    def measure_latency_under_load(self, concurrent_requests=50, duration_seconds=60):
        """Measure system latency under load"""
        self.logger.info(f"Measuring latency under load: {concurrent_requests} concurrent requests for {duration_seconds}s")
        
        # Clear previous latency data
        self.metrics['latency_metrics']['response_times'] = []
        
        # Load test parameters
        api_url = "http://localhost:5000/api/detect"
        test_data = {
            'frame_id': 'load_test',
            'user_id': 'load_test_user'
        }
        
        # Metrics tracking
        total_requests = 0
        successful_requests = 0
        failed_requests = 0
        response_times = []
        
        # Load test function
        def make_request():
            nonlocal total_requests, successful_requests, failed_requests, response_times
            
            start_time = time.perf_counter()
            try:
                response = requests.post(api_url, json=test_data, timeout=10)
                end_time = time.perf_counter()
                
                response_time = (end_time - start_time) * 1000
                response_times.append(response_time)
                
                total_requests += 1
                if response.status_code == 200:
                    successful_requests += 1
                else:
                    failed_requests += 1
                    
            except Exception as e:
                end_time = time.perf_counter()
                response_time = (end_time - start_time) * 1000
                response_times.append(response_time)
                
                total_requests += 1
                failed_requests += 1
        
        # Run load test
        end_time = time.time() + duration_seconds
        
        with ThreadPoolExecutor(max_workers=concurrent_requests) as executor:
            futures = []
            
            while time.time() < end_time:
                # Submit requests
                for _ in range(concurrent_requests):
                    if time.time() < end_time:
                        future = executor.submit(make_request)
                        futures.append(future)
                
                # Wait for some requests to complete
                time.sleep(0.1)
        
        # Wait for remaining requests
        for future in as_completed(futures):
            try:
                future.result()
            except:
                pass
        
        # Calculate latency metrics
        if response_times:
            avg_response_time = np.mean(response_times)
            p95_response_time = np.percentile(response_times, 95)
            p99_response_time = np.percentile(response_times, 99)
            max_response_time = np.max(response_times)
            min_response_time = np.min(response_times)
            
            self.metrics['latency_metrics'].update({
                'avg_response_time_ms': avg_response_time,
                'p95_response_time_ms': p95_response_time,
                'p99_response_time_ms': p99_response_time,
                'max_response_time_ms': max_response_time,
                'min_response_time_ms': min_response_time,
                'response_times': response_times
            })
        
        # Calculate throughput
        actual_duration = duration_seconds
        requests_per_second = total_requests / actual_duration
        
        self.metrics['throughput_metrics'].update({
            'requests_per_second': requests_per_second,
            'peak_throughput': requests_per_second
        })
        
        # Calculate success rate
        success_rate = (successful_requests / total_requests) * 100 if total_requests > 0 else 0
        
        self.logger.info(f"Load test completed:")
        self.logger.info(f"  Total requests: {total_requests}")
        self.logger.info(f"  Successful: {successful_requests} ({success_rate:.1f}%)")
        self.logger.info(f"  Failed: {failed_requests}")
        self.logger.info(f"  Requests/sec: {requests_per_second:.1f}")
        self.logger.info(f"  Avg response time: {avg_response_time:.2f}ms")
        self.logger.info(f"  P95 response time: {p95_response_time:.2f}ms")
        self.logger.info(f"  P99 response time: {p99_response_time:.2f}ms")
        
        return {
            'total_requests': total_requests,
            'success_rate': success_rate,
            'requests_per_second': requests_per_second,
            'avg_response_time_ms': avg_response_time,
            'p95_response_time_ms': p95_response_time,
            'p99_response_time_ms': p99_response_time
        }
    
    def monitor_system_resources(self, duration_seconds=300):
        """Monitor system resources over time"""
        self.logger.info(f"Monitoring system resources for {duration_seconds} seconds...")
        
        self.metrics['resource_metrics']['cpu_usage_percent'] = []
        self.metrics['resource_metrics']['memory_usage_percent'] = []
        
        start_time = time.time()
        
        while time.time() - start_time < duration_seconds:
            # Collect system metrics
            cpu_percent = psutil.cpu_percent(interval=1)
            memory_percent = psutil.virtual_memory().percent
            disk_percent = psutil.disk_usage('/').percent
            
            self.metrics['resource_metrics']['cpu_usage_percent'].append(cpu_percent)
            self.metrics['resource_metrics']['memory_usage_percent'].append(memory_percent)
            self.metrics['resource_metrics']['disk_usage_percent'] = disk_percent
            
            time.sleep(5)  # Sample every 5 seconds
        
        # Calculate averages
        if self.metrics['resource_metrics']['cpu_usage_percent']:
            avg_cpu = np.mean(self.metrics['resource_metrics']['cpu_usage_percent'])
            avg_memory = np.mean(self.metrics['resource_metrics']['memory_usage_percent'])
            
            self.metrics['resource_metrics']['avg_cpu_usage'] = avg_cpu
            self.metrics['resource_metrics']['avg_memory_usage'] = avg_memory
        
        self.logger.info(f"Resource monitoring completed:")
        self.logger.info(f"  Average CPU usage: {avg_cpu:.1f}%")
        self.logger.info(f"  Average memory usage: {avg_memory:.1f}%")
        self.logger.info(f"  Disk usage: {disk_percent:.1f}%")
    
    def simulate_session_metrics(self, num_sessions=10000):
        """Simulate session metrics for cost calculation"""
        self.logger.info(f"Simulating metrics for {num_sessions} sessions...")
        
        # Simulate session durations (in milliseconds)
        session_durations = np.random.normal(5000, 2000, num_sessions)  # 5s avg, 2s std
        session_durations = np.clip(session_durations, 1000, 30000)  # 1s to 30s range
        
        # Simulate success/failure rates
        success_rate = 0.98  # 98% success rate
        successful_sessions = int(num_sessions * success_rate)
        failed_sessions = num_sessions - successful_sessions
        
        # Calculate metrics
        avg_session_duration = np.mean(session_durations)
        
        self.metrics['session_metrics'].update({
            'total_sessions': num_sessions,
            'successful_sessions': successful_sessions,
            'failed_sessions': failed_sessions,
            'avg_session_duration_ms': avg_session_duration
        })
        
        # Calculate sessions per hour (assuming uniform distribution)
        sessions_per_hour = num_sessions / 24  # Assume sessions spread over 24 hours
        
        self.metrics['session_metrics']['sessions_per_hour'] = sessions_per_hour
        
        self.logger.info(f"Session simulation completed:")
        self.logger.info(f"  Total sessions: {num_sessions}")
        self.logger.info(f"  Successful: {successful_sessions} ({success_rate*100:.1f}%)")
        self.logger.info(f"  Failed: {failed_sessions}")
        self.logger.info(f"  Avg session duration: {avg_session_duration:.0f}ms")
        self.logger.info(f"  Sessions per hour: {sessions_per_hour:.0f}")
    
    def generate_performance_report(self):
        """Generate comprehensive performance report"""
        self.logger.info("Generating performance report...")
        
        # Calculate all metrics
        self.calculate_infrastructure_costs()
        self.simulate_session_metrics(10000)
        
        # Run load test if production server is running
        try:
            response = requests.get('http://localhost:5000/health', timeout=5)
            if response.status_code == 200:
                self.measure_latency_under_load(concurrent_requests=20, duration_seconds=30)
                self.monitor_system_resources(duration_seconds=60)
        except:
            self.logger.warning("Production server not available for load testing")
        
        # Create report
        report = {
            'report_timestamp': datetime.now().isoformat(),
            'performance_summary': {
                'total_sessions_tested': self.metrics['session_metrics']['total_sessions'],
                'success_rate': (self.metrics['session_metrics']['successful_sessions'] / 
                               self.metrics['session_metrics']['total_sessions']) * 100,
                'avg_session_duration_ms': self.metrics['session_metrics']['avg_session_duration_ms'],
                'sessions_per_hour': self.metrics['session_metrics']['sessions_per_hour']
            },
            'cost_analysis': {
                'cost_per_10k_sessions': self.metrics['cost_metrics']['compute_costs_per_10k_sessions'],
                'infrastructure_cost_per_hour': self.metrics['cost_metrics']['infrastructure_costs_per_hour'],
                'estimated_monthly_cost': self.metrics['cost_metrics']['total_monthly_cost'],
                'cost_per_session': (self.metrics['cost_metrics']['compute_costs_per_10k_sessions'] / 10000)
            },
            'performance_analysis': {
                'avg_response_time_ms': self.metrics['latency_metrics']['avg_response_time_ms'],
                'p95_response_time_ms': self.metrics['latency_metrics']['p95_response_time_ms'],
                'p99_response_time_ms': self.metrics['latency_metrics']['p99_response_time_ms'],
                'requests_per_second': self.metrics['throughput_metrics']['requests_per_second'],
                'peak_throughput': self.metrics['throughput_metrics']['peak_throughput']
            },
            'resource_utilization': {
                'avg_cpu_usage_percent': self.metrics['resource_metrics']['avg_cpu_usage'],
                'avg_memory_usage_percent': self.metrics['resource_metrics']['avg_memory_usage'],
                'disk_usage_percent': self.metrics['resource_metrics']['disk_usage_percent'][-1] if self.metrics['resource_metrics']['disk_usage_percent'] else 0
            },
            'infrastructure_status': self.metrics['infrastructure_metrics'],
            'detailed_metrics': self.metrics,
            'cost_breakdown': {
                'server_costs': self.cost_params['server_cost_per_hour'] * 24 * 30,
                'database_costs': self.cost_params['database_cost_per_hour'] * 24 * 30,
                'load_balancer_costs': self.cost_params['load_balancer_cost_per_hour'] * 24 * 30,
                'storage_costs': self.metrics['cost_metrics']['storage_costs_per_month']
            }
        }
        
        # Save report
        report_path = os.path.join(self.production_path, "performance_metrics_report.json")
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2)
        
        self.logger.info(f"Performance report saved: {report_path}")
        
        # Print summary
        self.print_performance_summary(report)
        
        return report_path
    
    def print_performance_summary(self, report):
        """Print performance summary"""
        print(f"\nüìà STELLOR LOGIC AI - PERFORMANCE METRICS REPORT")
        print("=" * 60)
        
        summary = report['performance_summary']
        costs = report['cost_analysis']
        performance = report['performance_analysis']
        resources = report['resource_utilization']
        
        print(f"üìä SESSION METRICS:")
        print(f"   üîÑ Total Sessions: {summary['total_sessions_tested']:,}")
        print(f"   ‚úÖ Success Rate: {summary['success_rate']:.1f}%")
        print(f"   ‚è±Ô∏è Avg Session Duration: {summary['avg_session_duration_ms']:.0f}ms")
        print(f"   üìà Sessions/Hour: {summary['sessions_per_hour']:.0f}")
        
        print(f"\nüí∞ COST ANALYSIS:")
        print(f"   üíµ Cost per 10K Sessions: ${costs['cost_per_10k_sessions']:.2f}")
        print(f"   üíµ Cost per Session: ${costs['cost_per_session']:.4f}")
        print(f"   üíµ Hourly Infrastructure Cost: ${costs['infrastructure_cost_per_hour']:.4f}")
        print(f"   üíµ Estimated Monthly Cost: ${costs['estimated_monthly_cost']:.2f}")
        
        print(f"\n‚ö° PERFORMANCE ANALYSIS:")
        print(f"   üìä Avg Response Time: {performance['avg_response_time_ms']:.2f}ms")
        print(f"   üìä P95 Response Time: {performance['p95_response_time_ms']:.2f}ms")
        print(f"   üìä P99 Response Time: {performance['p99_response_time_ms']:.2f}ms")
        print(f"   üöÄ Requests/Second: {performance['requests_per_second']:.1f}")
        print(f"   üöÄ Peak Throughput: {performance['peak_throughput']:.1f} RPS")
        
        print(f"\nüñ•Ô∏è RESOURCE UTILIZATION:")
        print(f"   üìä Avg CPU Usage: {resources['avg_cpu_usage_percent']:.1f}%")
        print(f"   üíæ Avg Memory Usage: {resources['avg_memory_usage_percent']:.1f}%")
        print(f"   üíø Disk Usage: {resources['disk_usage_percent']:.1f}%")
        
        print(f"\nüéØ PERFORMANCE TARGETS:")
        avg_response = performance['avg_response_time_ms']
        cost_per_10k = costs['cost_per_10k_sessions']
        
        print(f"   ‚ö° Response Time <100ms: {'‚úÖ' if avg_response < 100 else '‚ùå'} ({avg_response:.2f}ms)")
        print(f"   üí∞ Cost per 10K < $50: {'‚úÖ' if cost_per_10k < 50 else '‚ùå'} (${cost_per_10k:.2f})")
        print(f"   üìà Throughput >100 RPS: {'‚úÖ' if performance['requests_per_second'] > 100 else '‚ùå'} ({performance['requests_per_second']:.1f} RPS)")
        
        # Overall assessment
        targets_met = (
            avg_response < 100 and
            cost_per_10k < 50 and
            performance['requests_per_second'] > 100
        )
        
        print(f"\nüèÜ OVERALL PERFORMANCE: {'‚úÖ EXCELLENT' if targets_met else '‚ö†Ô∏è NEEDS OPTIMIZATION'}")

if __name__ == "__main__":
    print("üìà STELLOR LOGIC AI - PERFORMANCE METRICS TRACKER")
    print("=" * 60)
    print("Tracking costs, latency, and infrastructure performance")
    print("=" * 60)
    
    tracker = PerformanceMetricsTracker()
    
    try:
        # Generate comprehensive performance report
        report_path = tracker.generate_performance_report()
        
        print(f"\nüéâ PERFORMANCE METRICS ANALYSIS COMPLETED!")
        print(f"‚úÖ Costs per 10K sessions calculated")
        print(f"‚úÖ Infrastructure costs tracked")
        print(f"‚úÖ Latency under load measured")
        print(f"‚úÖ Resource utilization monitored")
        print(f"üìÑ Report saved: {report_path}")
        
    except Exception as e:
        print(f"‚ùå Performance analysis failed: {str(e)}")
        import traceback
        traceback.print_exc()
