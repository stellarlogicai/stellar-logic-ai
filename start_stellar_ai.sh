#!/bin/bash

# Stellar Logic AI - LLM Integration Startup Script
# This script starts Ollama, the Stellar LLM server, and the dashboard

echo "ðŸš€ Starting Stellar Logic AI with Ollama Integration..."

# Check if Ollama is running
echo "ðŸ” Checking Ollama status..."
if ! curl -s http://localhost:11434/api/tags > /dev/null 2>&1; then
    echo "âŒ Ollama is not running. Please start Ollama first:"
    echo "   Run: ollama serve"
    echo "   Then run this script again."
    exit 1
else
    echo "âœ… Ollama is running!"
fi

# Check if Stellar Logic AI model exists
echo "ðŸ” Checking for Stellar Logic AI model..."
if curl -s http://localhost:11434/api/tags | grep -q "stellar-logic-ai"; then
    echo "âœ… Stellar Logic AI model found!"
else
    echo "âš ï¸  Stellar Logic AI model not found. Available models:"
    curl -s http://localhost:11434/api/tags | python3 -c "
import json, sys
data = json.load(sys.stdin)
for model in data.get('models', []):
    print(f'  â€¢ {model[\"name\"]}')
"
    echo ""
    echo "ðŸ’¡ To create your Stellar Logic AI model:"
    echo "   ollama create stellar-logic-ai -f ./modelfile"
    echo "   (You'll need to create a Modelfile first)"
fi

# Start Stellar LLM Server
echo "ðŸŒ Starting Stellar LLM Server..."
python3 stellar_llm_server.py &
LLM_SERVER_PID=$!

# Wait for LLM server to start
echo "â³ Waiting for LLM server to start..."
sleep 3

# Check if LLM server is running
if curl -s http://localhost:5000/api/health > /dev/null 2>&1; then
    echo "âœ… Stellar LLM Server is running!"
else
    echo "âŒ Stellar LLM Server failed to start. Check the logs above."
    kill $LLM_SERVER_PID 2>/dev/null
    exit 1
fi

# Start Dashboard Server
echo "ðŸŽ¯ Starting Dashboard Server..."
python3 dashboard_server.py &
DASHBOARD_SERVER_PID=$!

# Wait for dashboard server to start
echo "â³ Waiting for Dashboard Server to start..."
sleep 2

# Check if dashboard server is running
if curl -s http://localhost:8000 > /dev/null 2>&1; then
    echo "âœ… Dashboard Server is running!"
else
    echo "âŒ Dashboard Server failed to start. Check the logs above."
    kill $LLM_SERVER_PID $DASHBOARD_SERVER_PID 2>/dev/null
    exit 1
fi

echo ""
echo "ðŸŽŠ All services are running!"
echo ""
echo "ðŸ“± Dashboard: http://localhost:8000"
echo "ðŸ¤– LLM API: http://localhost:5000"
echo "ðŸŒ Ollama: http://localhost:11434"
echo ""
echo "ðŸ’¡ Try these commands in the dashboard AI chat:"
echo "   â€¢ 'Generate email for Sarah Chen'"
echo "   â€¢ 'Research gaming market trends'"
echo "   â€¢ 'Optimize my schedule for investor meetings'"
echo "   â€¢ 'Create a business plan for investors'"
echo ""
echo "ðŸ›‘ To stop all services: Ctrl+C or kill processes $LLM_SERVER_PID and $DASHBOARD_SERVER_PID"

# Keep script running and handle shutdown
trap 'echo "ðŸ›‘ Shutting down services..."; kill $LLM_SERVER_PID $DASHBOARD_SERVER_PID 2>/dev/null; exit' INT TERM

# Wait for user to stop
wait
