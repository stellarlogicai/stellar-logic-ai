<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Stellar Logic AI - Multi-Model Command Center</title>
    <link rel="icon" href="favicon_32x32.png" type="image/png" sizes="32x32">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            color: white;
        }
        
        .container {
            max-width: 2200px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .header {
            text-align: center;
            padding: 30px 20px;
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            border-radius: 20px;
            margin-bottom: 30px;
            border: 2px solid rgba(255, 255, 255, 0.2);
        }
        
        .header h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
        }
        
        .header .subtitle {
            font-size: 1.2em;
            opacity: 0.9;
        }
        
        .main-layout {
            display: grid;
            grid-template-columns: 1fr 1fr 1fr 1fr;
            gap: 20px;
        }
        
        .card {
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            border-radius: 20px;
            padding: 20px;
            border: 2px solid rgba(255, 255, 255, 0.2);
        }
        
        .card-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 15px;
        }
        
        .card-title {
            font-size: 1.3em;
            font-weight: bold;
        }
        
        .alert-badge {
            background: #ef4444;
            color: white;
            border-radius: 50%;
            width: 20px;
            height: 20px;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 0.6em;
            font-weight: bold;
            animation: pulse 2s infinite;
        }
        
        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.1); }
            100% { transform: scale(1); }
        }
        
        .model-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(140px, 1fr));
            gap: 12px;
            margin-bottom: 15px;
        }
        
        .model-item {
            background: rgba(255, 255, 255, 0.05);
            border-radius: 15px;
            padding: 15px;
            text-align: center;
            border: 2px solid rgba(255, 255, 255, 0.1);
            cursor: pointer;
            transition: all 0.3s ease;
        }
        
        .model-item:hover {
            background: rgba(255, 255, 255, 0.1);
            transform: translateY(-2px);
        }
        
        .model-item.active {
            border-color: #10b981;
            background: rgba(16, 185, 129, 0.1);
        }
        
        .model-item.busy {
            border-color: #f59e0b;
            background: rgba(245, 158, 11, 0.1);
        }
        
        .model-item.offline {
            border-color: #ef4444;
            background: rgba(239, 68, 68, 0.1);
            opacity: 0.7;
        }
        
        .model-name {
            font-weight: bold;
            font-size: 0.9em;
            margin-bottom: 5px;
        }
        
        .model-status {
            font-size: 0.7em;
            margin-bottom: 5px;
        }
        
        .model-metrics {
            font-size: 0.6em;
            opacity: 0.8;
        }
        
        .task-item {
            background: rgba(255, 255, 255, 0.05);
            border-radius: 15px;
            padding: 12px;
            margin-bottom: 10px;
            border: 2px solid rgba(255, 255, 255, 0.1);
            cursor: pointer;
            transition: all 0.3s ease;
        }
        
        .task-item:hover {
            background: rgba(255, 255, 255, 0.1);
            transform: translateY(-2px);
        }
        
        .task-item.urgent {
            border-color: #ef4444;
            background: rgba(239, 68, 68, 0.1);
        }
        
        .task-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 8px;
        }
        
        .task-title {
            font-weight: bold;
            font-size: 0.9em;
        }
        
        .task-model {
            background: rgba(251, 191, 36, 0.2);
            border-radius: 20px;
            padding: 4px 8px;
            font-size: 0.6em;
        }
        
        .task-meta {
            display: flex;
            gap: 10px;
            font-size: 0.7em;
            opacity: 0.8;
            margin-bottom: 8px;
        }
        
        .task-description {
            font-size: 0.8em;
            line-height: 1.3;
            margin-bottom: 8px;
        }
        
        .action-buttons {
            display: flex;
            gap: 6px;
            flex-wrap: wrap;
        }
        
        .btn {
            border: none;
            padding: 4px 8px;
            border-radius: 12px;
            font-size: 0.6em;
            font-weight: bold;
            cursor: pointer;
            transition: all 0.3s ease;
        }
        
        .btn-approve {
            background: linear-gradient(135deg, #10b981, #059669);
            color: white;
        }
        
        .btn-reassign {
            background: linear-gradient(135deg, #8b5cf6, #7c3aed);
            color: white;
        }
        
        .btn-details {
            background: rgba(255, 255, 255, 0.1);
            color: white;
            border: 1px solid rgba(255, 255, 255, 0.2);
        }
        
        .ai-chat {
            height: 300px;
            display: flex;
            flex-direction: column;
        }
        
        .chat-messages {
            flex: 1;
            overflow-y: auto;
            padding: 12px;
            background: rgba(0, 0, 0, 0.2);
            border-radius: 15px;
            margin-bottom: 10px;
            font-size: 0.8em;
        }
        
        .message {
            margin-bottom: 10px;
            padding: 8px 12px;
            border-radius: 15px;
            max-width: 80%;
        }
        
        .message.ai {
            background: rgba(251, 191, 36, 0.2);
            border-left: 3px solid #fbbf24;
            align-self: flex-start;
        }
        
        .message.user {
            background: rgba(255, 255, 255, 0.1);
            align-self: flex-end;
        }
        
        .message.model {
            background: rgba(139, 92, 246, 0.2);
            border-left: 3px solid #8b5cf6;
            align-self: flex-start;
        }
        
        .message.alert {
            background: rgba(239, 68, 68, 0.2);
            border-left: 3px solid #ef4444;
            animation: pulse 2s infinite;
        }
        
        .chat-input {
            display: flex;
            gap: 8px;
        }
        
        .chat-input input {
            flex: 1;
            padding: 8px 12px;
            background: rgba(255, 255, 255, 0.1);
            border: 2px solid rgba(255, 255, 255, 0.2);
            border-radius: 20px;
            color: white;
            font-size: 0.8em;
        }
        
        .chat-input input:focus {
            outline: none;
            border-color: #fbbf24;
            background: rgba(255, 255, 255, 0.15);
        }
        
        .chat-input button {
            background: linear-gradient(135deg, #fbbf24, #f59e0b);
            color: #1f2937;
            border: none;
            padding: 8px 15px;
            border-radius: 20px;
            font-weight: bold;
            cursor: pointer;
            transition: all 0.3s ease;
            font-size: 0.8em;
        }
        
        .quick-actions {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 8px;
        }
        
        .quick-btn {
            background: rgba(255, 255, 255, 0.1);
            border: 2px solid rgba(255, 255, 255, 0.2);
            color: white;
            padding: 10px;
            border-radius: 12px;
            cursor: pointer;
            transition: all 0.3s ease;
            text-align: center;
            font-size: 0.7em;
        }
        
        .quick-btn:hover {
            background: rgba(255, 255, 255, 0.2);
            transform: translateY(-1px);
        }
        
        .performance-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 10px;
            margin-bottom: 15px;
        }
        
        .perf-item {
            background: rgba(255, 255, 255, 0.05);
            border-radius: 10px;
            padding: 10px;
            text-align: center;
        }
        
        .perf-value {
            font-size: 1.1em;
            font-weight: bold;
            margin-bottom: 3px;
        }
        
        .perf-label {
            font-size: 0.6em;
            opacity: 0.8;
        }
        
        @media (max-width: 1800px) {
            .main-layout {
                grid-template-columns: 1fr 1fr 1fr;
            }
        }
        
        @media (max-width: 1400px) {
            .main-layout {
                grid-template-columns: 1fr 1fr;
            }
        }
        
        @media (max-width: 1000px) {
            .main-layout {
                grid-template-columns: 1fr;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>üß† Multi-Model AI Command Center</h1>
            <p class="subtitle">Intelligent Model Orchestration & Task Distribution System</p>
        </div>
        
        <div class="main-layout">
            <!-- AI Model Status -->
            <div class="card">
                <div class="card-header">
                    <h2 class="card-title">ü§ñ AI Model Fleet</h2>
                    <div class="alert-badge">2</div>
                </div>
                
                <div class="model-grid" id="modelGrid">
                    <!-- Models will be populated here -->
                </div>
                
                <div style="font-size: 0.8em; line-height: 1.4; margin-bottom: 15px;">
                    <h4 style="color: #fbbf24; margin-bottom: 8px;">üß† Current Model Capabilities:</h4>
                    <strong>Stellar Logic AI:</strong> Core business logic, approvals + LEARNING HUB<br>
                    <strong>Llama 3.1 3B:</strong> Advanced reasoning, analysis (teacher model)<br>
                    <strong>CodeLlama 3B:</strong> Code generation, technical tasks (teacher model)<br>
                    <strong>Mistral 3B:</strong> Creative content, marketing (teacher model)<br>
                    <strong>Qwen 3B:</strong> Multilingual, data processing (teacher model)<br>
                    <strong>Nous-Hermes 3B:</strong> Complex problem solving (teacher model)<br><br>
                    
                    <strong>üöÄ Ultra-Lightweight Backup Models:</strong><br>
                    <strong>Phi-2 2.7B:</strong> Quick reasoning, lightweight analysis (teacher model)<br>
                    <strong>TinyLlama 1.1B:</strong> Fast responses, basic tasks (teacher model)<br>
                    <strong>Gemma 2B:</strong> Efficient reasoning, multilingual (teacher model)<br>
                    <strong>StableLM-3B:</strong> Quick content generation (teacher model)<br><br>
                    
                    <strong>üß† Stellar Logic AI Learning System:</strong><br>
                    ‚Ä¢ Learns reasoning patterns from Llama 3.1<br>
                    ‚Ä¢ Learns code generation from CodeLlama<br>
                    ‚Ä¢ Learns creativity from Mistral<br>
                    ‚Ä¢ Learns multilingual from Qwen & Gemma<br>
                    ‚Ä¢ Learns problem-solving from Nous-Hermes<br>
                    ‚Ä¢ Becomes unified AI system over time<br><br>
                    
                    <strong>üí° Hardware Optimized:</strong> All models sized for 16GB RAM + GTX 1080
                </div>
            </div>
            
            <!-- Active Task Distribution -->
            <div class="card">
                <div class="card-header">
                    <h2 class="card-title">‚ö° Active Task Distribution</h2>
                    <div class="alert-badge">8</div>
                </div>
                
                <div id="taskList">
                    <!-- Tasks will be populated here -->
                </div>
            </div>
            
            <!-- Model Performance Analytics -->
            <div class="card">
                <div class="card-header">
                    <h2 class="card-title">üìä Model Performance</h2>
                </div>
                
                <div class="performance-grid">
                    <div class="perf-item">
                        <div class="perf-value">94%</div>
                        <div class="perf-label">Overall Accuracy</div>
                    </div>
                    <div class="perf-item">
                        <div class="perf-value">1.2s</div>
                        <div class="perf-label">Avg Response Time</div>
                    </div>
                    <div class="perf-item">
                        <div class="perf-value">847</div>
                        <div class="perf-label">Tasks Completed</div>
                    </div>
                    <div class="perf-item">
                        <div class="perf-value">98%</div>
                        <div class="perf-label">Uptime</div>
                    </div>
                </div>
                
                <div style="font-size: 0.8em; line-height: 1.4;">
                    <h4 style="color: #fbbf24; margin-bottom: 8px;">üèÜ Top Performers:</h4>
                    <strong>1. Stellar Logic AI:</strong> 97% accuracy, approvals<br>
                    <strong>2. Llama 3.1:</strong> 95% accuracy, analysis<br>
                    <strong>3. Mistral:</strong> 93% accuracy, creative<br><br>
                    
                    <strong>üìà Efficiency Gains:</strong><br>
                    ‚Ä¢ 40% faster task completion<br>
                    ‚Ä¢ 25% better quality output<br>
                    ‚Ä¢ 60% reduced manual intervention
                </div>
            </div>
            
            <!-- Multi-Model Assistant -->
            <div class="card ai-chat">
                <div class="card-header">
                    <h2 class="card-title">üß† Multi-Model Assistant</h2>
                    <div class="alert-badge">5</div>
                </div>
                
                <div class="chat-messages" id="multiChatMessages">
                    <div class="message ai alert">
                        üß† <strong>MODEL ALERT:</strong> Llama 3.1 handling complex pricing analysis, Mistral creating visual content!
                    </div>
                    <div class="message model">
                        ü¶ô <strong>Llama 3.1:</strong> "Completed GameStudio X pricing analysis. Recommend 15% discount with 3-month support package. Confidence: 94%"
                    </div>
                    <div class="message model">
                        üé® <strong>Mistral:</strong> "Created 3 new infographics for Instagram. Optimized for maximum engagement. Ready for approval."
                    </div>
                    <div class="message ai">
                        ‚ö° <strong>Task Distribution:</strong> 8 active tasks across 4 models. All systems operating at optimal capacity.
                    </div>
                    <div class="message model">
                        üíª <strong>CodeLlama:</strong> "Generated API integration code for Thunderbolt Studios. Testing shows 99.9% uptime compatibility."
                    </div>
                </div>
                
                <div class="chat-input">
                    <input type="text" id="multiChatInput" placeholder="Ask models about tasks, performance, or capabilities..." onkeypress="handleMultiChatInput(event)">
                    <button onclick="sendMultiMessage()">Send</button>
                </div>
            </div>
            
            <!-- Quick Actions -->
            <div class="card">
                <div class="card-header">
                    <h2 class="card-title">‚ö° Quick Actions</h2>
                </div>
                
                <div class="quick-actions">
                    <button class="quick-btn" onclick="optimizeDistribution()">
                        üéØ Optimize Distribution
                    </button>
                    <button class="quick-btn" onclick="upgradeModels()">
                        üöÄ Upgrade Models
                    </button>
                    <button class="quick-btn" onclick="reassignTasks()">
                        üîÑ Reassign Tasks
                    </button>
                    <button class="quick-btn" onclick="modelHealth()">
                        üè• Model Health Check
                    </button>
                    <button class="quick-btn" onclick="performanceReport()">
                        üìä Performance Report
                    </button>
                    <button class="quick-btn" onclick="scaleModels()">
                        üìà Scale Models
                    </button>
                </div>
            </div>
            
            <!-- Ollama Integration -->
            <div class="card">
                <div class="card-header">
                    <h2 class="card-title">ü¶ô Ollama Integration</h2>
                </div>
                
                <div style="font-size: 0.8em; line-height: 1.4;">
                    <h4 style="color: #fbbf24; margin-bottom: 8px;">üöÄ Current Hardware Optimization:</h4>
                    <strong>‚úÖ Primary Models (Optimized for 16GB RAM):</strong><br>
                    ‚Ä¢ Llama 3.1 3B ‚Üí Llama 3.2 3B (same size, better performance)<br>
                    ‚Ä¢ Mistral 3B ‚Üí Mistral 7B (if RAM allows)<br>
                    ‚Ä¢ Qwen 3B ‚Üí Qwen 7B (if RAM allows)<br>
                    ‚Ä¢ CodeLlama 3B ‚Üí CodeLlama 7B (if RAM allows)<br><br>
                    
                    <strong>ÔøΩ Ultra-Lightweight Backup Models:</strong><br>
                    ‚Ä¢ Phi-2 2.7B: Quick reasoning when 3B models are busy<br>
                    ‚Ä¢ TinyLlama 1.1B: Fast responses for basic tasks<br>
                    ‚Ä¢ Gemma 2B: Efficient reasoning, multilingual support<br>
                    ‚Ä¢ StableLM-3B: Quick content generation<br><br>
                    
                    <strong>ÔøΩÔøΩÔ∏è Current Hardware:</strong><br>
                    ‚Ä¢ 16GB RAM (current constraint)<br>
                    ‚Ä¢ GTX 1080 (8GB VRAM)<br>
                    ‚Ä¢ Can run 2-3 small models simultaneously<br>
                    ‚Ä¢ Model switching: 3-5 seconds (lightweight models)<br><br>
                    
                    <strong>üìà Bottleneck Prevention:</strong><br>
                    ‚Ä¢ Auto-switch to lightweight models when 3B models are busy<br>
                    ‚Ä¢ Priority-based model selection (3B ‚Üí 2.7B ‚Üí 1.1B)<br>
                    ‚Ä¢ Multi-model parallel processing (2-3 models at once)<br>
                    ‚Ä¢ Smart load balancing across available RAM<br>
                    ‚Ä¢ Model caching for frequently used lightweight models
                </div>
            </div>
            
            <!-- System Integration -->
            <div class="card">
                <div class="card-header">
                    <h2 class="card-title">üîó System Integration</h2>
                </div>
                
                <div style="font-size: 0.8em; line-height: 1.4;">
                    <h4 style="color: #fbbf24; margin-bottom: 8px;">üåê Integrated Dashboards:</h4>
                    <strong>üåê Integrated Dashboards:</strong><br>
                    ‚Ä¢ ü§ñ Integrated Assistant Dashboard ‚Üí Learning Hub<br>
                    ‚Ä¢ üíº Advanced Sales & Pricing ‚Üí Teacher models + Learning Hub<br>
                    ‚Ä¢ üì± Visual Social Media ‚Üí Creative models + Learning Hub<br>
                    ‚Ä¢ üìã Unified Approval System ‚Üí Core approvals + Learning Hub<br>
                    ‚Ä¢ üîß Technical Operations ‚Üí Code models + Learning Hub<br>
                    ‚Ä¢ üìä Analytics & Reporting ‚Üí All models feed into Learning Hub<br><br>
                    
                    <strong>üîÑ Learning Data Flow:</strong><br>
                    ‚Ä¢ All dashboard activities ‚Üí Learning Hub analysis<br>
                    ‚Ä¢ Teacher model decisions ‚Üí Stellar Logic AI learns patterns<br>
                    ‚Ä¢ User approvals ‚Üí Learning Hub refines understanding<br>
                    ‚Ä¢ Performance metrics ‚Üí Learning Hub optimizes integration<br>
                    ‚Ä¢ User feedback ‚Üí Learning Hub adapts behavior<br><br>
                    
                    <strong>üéØ Unified Experience:</strong><br>
                    ‚Ä¢ Single dashboard controls all AI operations<br>
                    ‚Ä¢ Learning Hub learns from all dashboard activities<br>
                    ‚Ä¢ Stellar Logic AI becomes unified AI system<br>
                    ‚Ä¢ No page bouncing - everything integrated!<br><br>
                    
                    <strong>üîÑ Model Assignment Logic:</strong><br>
                    ‚Ä¢ <strong>Stellar Logic AI:</strong> Core decisions, approvals + Learning Hub<br>
                    ‚Ä¢ <strong>Llama 3.1:</strong> Complex analysis, pricing (teacher)<br>
                    ‚Ä¢ <strong>Mistral:</strong> Creative content, visuals (teacher)<br>
                    ‚Ä¢ <strong>CodeLlama:</strong> Technical tasks, code (teacher)<br>
                    ‚Ä¢ <strong>Qwen:</strong> Data processing, multilingual (teacher)<br>
                    ‚Ä¢ <strong>Nous-Hermes:</strong> Problem solving (teacher)<br><br>
                    
                    <strong>üéØ Auto-Failover:</strong> If model fails ‚Üí auto-reassign to next best model
                </div>
            </div>
        </div>
    </div>
    
    <script>
        const modelsData = [
            {
                id: 'stellar-logic',
                name: 'Stellar Logic AI',
                status: 'active',
                accuracy: '94%',
                load: '65%',
                tasks: 18,
                specialty: 'Core Business Logic + Learning Hub',
                size: '3B',
                learningProgress: '67%'
            },
            {
                id: 'llama-31',
                name: 'Llama 3.1 3B',
                status: 'active',
                accuracy: '89%',
                load: '88%',
                tasks: 12,
                specialty: 'Advanced Reasoning (Teacher Model)',
                size: '3B',
                teachingProgress: '82%'
            },
            {
                id: 'codellama',
                name: 'CodeLlama 3B',
                status: 'busy',
                accuracy: '87%',
                load: '95%',
                tasks: 6,
                specialty: 'Code Generation (Teacher Model)',
                size: '3B',
                teachingProgress: '74%'
            },
            {
                id: 'mistral',
                name: 'Mistral 3B',
                status: 'active',
                accuracy: '85%',
                load: '45%',
                tasks: 8,
                specialty: 'Creative Content (Teacher Model)',
                size: '3B',
                teachingProgress: '68%'
            },
            {
                id: 'qwen',
                name: 'Qwen 3B',
                status: 'active',
                accuracy: '83%',
                load: '30%',
                tasks: 4,
                specialty: 'Multilingual (Teacher Model)',
                size: '3B',
                teachingProgress: '71%'
            },
            {
                id: 'nous-hermes',
                name: 'Nous-Hermes 3B',
                status: 'offline',
                accuracy: '81%',
                load: '0%',
                tasks: 0,
                specialty: 'Problem Solving (Teacher Model)',
                size: '3B',
                teachingProgress: '65%'
            },
            {
                id: 'phi-2',
                name: 'Phi-2 2.7B',
                status: 'standby',
                accuracy: '78%',
                load: '0%',
                tasks: 0,
                specialty: 'Quick Reasoning (Teacher Model)',
                size: '2.7B',
                teachingProgress: '58%'
            },
            {
                id: 'tinyllama',
                name: 'TinyLlama 1.1B',
                status: 'standby',
                accuracy: '72%',
                load: '0%',
                tasks: 0,
                specialty: 'Fast Responses (Teacher Model)',
                size: '1.1B',
                teachingProgress: '52%'
            },
            {
                id: 'gemma',
                name: 'Gemma 2B',
                status: 'standby',
                accuracy: '76%',
                load: '0%',
                tasks: 0,
                specialty: 'Efficient Reasoning (Teacher Model)',
                size: '2B',
                teachingProgress: '61%'
            },
            {
                id: 'stablelm',
                name: 'StableLM-3B',
                status: 'standby',
                accuracy: '74%',
                load: '0%',
                tasks: 0,
                specialty: 'Quick Content (Teacher Model)',
                size: '3B',
                teachingProgress: '55%'
            }
        ];
        
        const tasksData = [
            {
                id: 1,
                title: 'GameStudio X Pricing Analysis',
                model: 'Llama 3.1 3B',
                priority: 'high',
                status: 'processing',
                description: 'Complex pricing negotiation with 30% discount request',
                progress: '85%',
                timeLeft: '2 minutes'
            },
            {
                id: 2,
                title: 'Instagram Infographic Creation',
                model: 'Mistral 3B',
                priority: 'medium',
                status: 'processing',
                description: 'Creating gaming security statistics visual',
                progress: '60%',
                timeLeft: '5 minutes'
            },
            {
                id: 3,
                title: 'API Integration Code',
                model: 'CodeLlama 3B',
                priority: 'high',
                status: 'processing',
                description: 'Thunderbolt Studios custom API integration',
                progress: '95%',
                timeLeft: '1 minute'
            },
            {
                id: 4,
                title: 'Social Media Campaign',
                model: 'Mistral 3B',
                priority: 'medium',
                status: 'queued',
                description: 'Weekly content creation for all platforms',
                progress: '0%',
                timeLeft: '10 minutes'
            },
            {
                id: 5,
                title: 'Customer Support Response',
                model: 'Stellar Logic AI',
                priority: 'urgent',
                status: 'processing',
                description: 'Urgent technical issue resolution needed',
                progress: '40%',
                timeLeft: '3 minutes'
            }
        ];
        
        function initializeDashboard() {
            renderModels();
            renderTasks();
            startRealTimeUpdates();
        }
        
        function renderModels() {
            const container = document.getElementById('modelGrid');
            
            container.innerHTML = modelsData.map(model => `
                <div class="model-item ${model.status}" onclick="selectModel('${model.id}')">
                    <div class="model-name">${model.name}</div>
                    <div class="model-status">${model.status.toUpperCase()}</div>
                    <div class="model-metrics">
                        Accuracy: ${model.accuracy}<br>
                        Load: ${model.load}<br>
                        Tasks: ${model.tasks}<br>
                        Size: ${model.size}<br>
                        ${model.specialty}<br>
                        ${model.teachingProgress ? `Teaching: ${model.teachingProgress}` : ''}
                        ${model.learningProgress ? `Learning: ${model.learningProgress}` : ''}
                    </div>
                </div>
            `).join('');
        }
        
        function renderTasks() {
            const container = document.getElementById('taskList');
            
            container.innerHTML = tasksData.map(task => `
                <div class="task-item ${task.priority === 'urgent' ? 'urgent' : ''}" onclick="showTaskDetails(${task.id})">
                    <div class="task-header">
                        <div class="task-title">${task.title}</div>
                        <div class="task-model">${task.model}</div>
                    </div>
                    <div class="task-meta">
                        <span>üéØ ${task.priority.toUpperCase()}</span>
                        <span>üìä ${task.progress}</span>
                        <span>‚è∞ ${task.timeLeft}</span>
                        <span>üîÑ ${task.status}</span>
                    </div>
                    <div class="task-description">${task.description}</div>
                    <div class="action-buttons">
                        <button class="btn btn-approve" onclick="approveTask(${task.id}, event)">‚úÖ</button>
                        <button class="btn btn-reassign" onclick="reassignTask(${task.id}, event)">üîÑ</button>
                        <button class="btn btn-details" onclick="showTaskDetails(${task.id}, event)">üìä</button>
                    </div>
                </div>
            `).join('');
        }
        
        function selectModel(modelId) {
            const model = modelsData.find(m => m.id === modelId);
            addMultiMessage(`üß† Selected: ${model.name}\n\nStatus: ${model.status}\nAccuracy: ${model.accuracy}\nLoad: ${model.load}\nActive Tasks: ${model.tasks}\nSpecialty: ${model.specialty}`, 'ai');
        }
        
        function approveTask(id, event) {
            event.stopPropagation();
            const task = tasksData.find(t => t.id === id);
            addMultiMessage(`‚úÖ Approved task: "${task.title}"\n\nModel: ${task.model}\nProgress: ${task.progress}\nPriority: ${task.priority}`, 'ai');
            
            const index = tasksData.findIndex(t => t.id === id);
            tasksData.splice(index, 1);
            renderTasks();
        }
        
        function reassignTask(id, event) {
            event.stopPropagation();
            const task = tasksData.find(t => t.id === id);
            const availableModels = modelsData.filter(m => m.status === 'active' && m.name !== task.model);
            
            addMultiMessage(`üîÑ Reassigning task: "${task.title}"\n\nCurrent: ${task.model}\nAvailable models: ${availableModels.map(m => m.name).join(', ')}\n\nSelect new model:`, 'ai');
        }
        
        function showTaskDetails(id, event) {
            event.stopPropagation();
            const task = tasksData.find(t => t.id === id);
            addMultiMessage(`üìä Task Details: "${task.title}"\n\nModel: ${task.model}\nPriority: ${task.priority}\nStatus: ${task.status}\nProgress: ${task.progress}\nTime Remaining: ${task.timeLeft}\n\nDescription: ${task.description}`, 'ai');
        }
        
        function optimizeDistribution() {
            addMultiMessage(`üéØ Optimizing task distribution...\n\nAnalyzing model loads and capabilities\nRebalancing tasks for maximum efficiency\nExpected improvement: 25% faster completion`, 'ai');
        }
        
        function upgradeModels() {
            addMultiMessage(`üöÄ Initiating model upgrade sequence...\n\nTarget upgrades:\n‚Ä¢ Llama 3.1 ‚Üí Llama 3.2 70B\n‚Ä¢ Mistral ‚Üí Mixtral 8x7B\n‚Ä¢ Qwen ‚Üí Qwen 72B\n\nHardware upgrade required: 128GB RAM, 2x RTX 4090\nEstimated cost: $8,000\nPerformance gain: 300-500%`, 'ai');
        }
        
        function reassignTasks() {
            addMultiMessage(`üîÑ Reassigning tasks for optimal performance...\n\nMoving tasks from overloaded models\nBalancing workload across available models\nExpected completion time: 2 minutes`, 'ai');
        }
        
        function modelHealth() {
            addMultiMessage(`üè• Running comprehensive model health check...\n\n‚úÖ Stellar Logic AI: Optimal\n‚úÖ Llama 3.1: Healthy\n‚ö†Ô∏è CodeLlama: High load (92%)\n‚úÖ Mistral: Optimal\n‚úÖ Qwen: Optimal\n‚ùå Nous-Hermes: Offline\n\nRecommendation: Restart CodeLlama, bring Nous-Hermes online`, 'ai');
        }
        
        function performanceReport() {
            addMultiMessage(`üìä Multi-Model Performance Report:\n\nüèÜ Top Performers:\n1. Stellar Logic AI: 97% accuracy\n2. Llama 3.1: 95% accuracy\n3. Mistral: 93% accuracy\n\nüìà System Metrics:\n‚Ä¢ Total tasks: 847 completed\n‚Ä¢ Average response: 1.2 seconds\n‚Ä¢ System uptime: 98%\n‚Ä¢ Error rate: <1%\n\nüí° Optimization: Consider upgrading CodeLlama to handle technical load`, 'ai');
        }
        
        function scaleModels() {
            addMultiMessage(`üìà Scaling model infrastructure...\n\nCurrent capacity: 6 models\nTarget capacity: 12 models\nScaling strategy:\n‚Ä¢ Add specialized models for each task type\n‚Ä¢ Implement load balancing\n‚Ä¢ Enable auto-scaling based on demand\n\nExpected improvement: 200% capacity increase`, 'ai');
        }
        
        function sendMultiMessage() {
            const input = document.getElementById('multiChatInput');
            const message = input.value.trim();
            
            if (message) {
                addMultiMessage(message, 'user');
                
                setTimeout(() => {
                    let response = generateMultiModelResponse(message);
                    addMultiMessage(response, 'model');
                }, 1000);
                
                input.value = '';
            }
        }
        
        function handleMultiChatInput(event) {
            if (event.key === 'Enter') {
                sendMultiMessage();
            }
        }
        
        function addMultiMessage(message, sender = 'ai') {
            const chatMessages = document.getElementById('multiChatMessages');
            const messageDiv = document.createElement('div');
            messageDiv.className = `message ${sender}`;
            if (sender === 'ai' && (message.includes('ALERT') || message.includes('üß†'))) {
                messageDiv.className += ' alert';
            }
            messageDiv.innerHTML = message;
            chatMessages.appendChild(messageDiv);
            chatMessages.scrollTop = chatMessages.scrollHeight;
        }
        
        function generateMultiModelResponse(message) {
            const lowerMessage = message.toLowerCase();
            
            if (lowerMessage.includes('model') || lowerMessage.includes('which')) {
                return `üß† <strong>Current Model Fleet Status:</strong><br><br>
ü§ñ <strong>Stellar Logic AI:</strong> Active, 97% accuracy, Core business logic<br>
ü¶ô <strong>Llama 3.1:</strong> Active, 95% accuracy, Advanced reasoning<br>
üíª <strong>CodeLlama:</strong> Busy, 94% accuracy, Code generation<br>
üé® <strong>Mistral:</strong> Active, 93% accuracy, Creative content<br>
üåç <strong>Qwen:</strong> Active, 91% accuracy, Multilingual<br>
üß† <strong>Nous-Hermes:</strong> Offline, 89% accuracy, Problem solving<br><br>
Total active models: 5/6<br>
System efficiency: 94%`;
            }
            
            if (lowerMessage.includes('task') || lowerMessage.includes('distribution')) {
                return `‚ö° <strong>Task Distribution Analysis:</strong><br><br>
üéØ <strong>Active Tasks:</strong> 8 total<br>
ü¶ô <strong>Llama 3.1:</strong> 3 tasks (complex analysis)<br>
üé® <strong>Mistral:</strong> 2 tasks (creative content)<br>
üíª <strong>CodeLlama:</strong> 1 task (technical)<br>
ü§ñ <strong>Stellar Logic AI:</strong> 1 task (approvals)<br>
üåç <strong>Qwen:</strong> 1 task (data processing)<br><br>
üìä <strong>Load Distribution:</strong><br>
‚Ä¢ CodeLlama: 92% load (consider reassigning)<br>
‚Ä¢ Llama 3.1: 78% load (optimal)<br>
‚Ä¢ Other models: <50% load (available)`;
            }
            
            if (lowerMessage.includes('upgrade') || lowerMessage.includes('ollama')) {
                return `üöÄ <strong>Ollama Upgrade Path:</strong><br><br>
üìà <strong>Recommended Upgrades:</strong><br>
‚Ä¢ Llama 3.1 8B ‚Üí Llama 3.2 70B (5x performance)<br>
‚Ä¢ Mistral 7B ‚Üí Mixtral 8x7B (3x performance)<br>
‚Ä¢ Qwen 7B ‚Üí Qwen 72B (4x performance)<br>
‚Ä¢ CodeLlama 13B ‚Üí CodeLlama 34B (2.5x performance)<br><br>
üõ†Ô∏è <strong>Hardware Requirements:</strong><br>
‚Ä¢ Current: 32GB RAM, RTX 4090<br>
‚Ä¢ Upgraded: 128GB RAM, 2x RTX 4090<br>
‚Ä¢ Cost: ~$8,000<br>
‚Ä¢ Timeline: 2-3 weeks<br><br>
üí∞ <strong>ROI:</strong> 300-500% performance gain, faster task completion`;
            }
            
            return `üß† I can help you with:<br><br>
‚Ä¢ ü§ñ Model status and performance<br>
‚Ä¢ ‚ö° Task distribution and optimization<br>
‚Ä¢ üöÄ Model upgrades and scaling<br>
‚Ä¢ üìä Performance analytics<br>
‚Ä¢ üîó System integration status<br>
‚Ä¢ üõ†Ô∏è Troubleshooting and health checks<br><br>
What would you like to know about the multi-model system?`;
        }
        
        function startRealTimeUpdates() {
            // Simulate real-time updates
            setInterval(() => {
                // Update model loads
                modelsData.forEach(model => {
                    if (model.status === 'active') {
                        const loadChange = Math.floor(Math.random() * 10) - 5;
                        model.load = Math.max(0, Math.min(100, parseInt(model.load) + loadChange)) + '%';
                    }
                });
                
                // Update task progress
                tasksData.forEach(task => {
                    if (task.status === 'processing') {
                        const progressIncrease = Math.floor(Math.random() * 15);
                        task.progress = Math.min(100, parseInt(task.progress) + progressIncrease) + '%';
                        
                        if (task.progress === '100%') {
                            task.status = 'completed';
                        }
                    }
                });
                
                renderModels();
                renderTasks();
            }, 5000); // Every 5 seconds
        }
        
        // Initialize on load
        document.addEventListener('DOMContentLoaded', initializeDashboard);
    </script>
</body>
</html>
